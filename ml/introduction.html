<html>

<head>
    <meta charset="UTF-8">
    <meta name="viewport"
        content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Document</title>
    <!--<link rel="stylesheet" href="https://pyscript.net/alpha/pyscript.css" />
    <script defer src="https://pyscript.net/alpha/pyscript.js"></script> -->

    <py-env>
        - matplotlib
        - numpy
    </py-env>
</head>

<body style="background-color:lightslategray;">
    <h1 align="center">Introduction to Machine Learning</h1>
    <h3 align="center">What is Machine Learning exactly?</h3>
    <p>Machine Learning is not a new idea. It is based on the model of brain
        cell interaction. This model was created in 1949 by Donald Hebb in a book titled "The Organization of Behavior".
        The book presents Hebb's theories on neuron excitement and communication between neurons. Arthur Samuel 
        designed a number of mechanisms allowing his program to become better. In what Samuel called rote learning, 
        his program recorded/remembered all positions it had already seen and combined this with the values
        of the reward function. Arthur Samuel coined the phrase “machine learning” in 1952. 
        In 1957, Frank Rosenblatt combined Donald Hebb's model of brain cell interaction with Arthur Samuel's
        machine learning efforts and created the perceptron.
        This is a quick summary of Machine Learning history. We has pretty huge advancements inbetween today and 
        1949. For example Deep Blue, the first computer to beat a GrandMaster at chess. Various facial recognition
        software, AlphaGo and so on.
    </p>
    <br>
    <br>
    <h2 align="center"><a href="https://en.wikipedia.org/wiki/Perceptron">Perceptron model Rosenblatt</a></h2>
    <img 
        src="https://slideplayer.com/slide/14135708/86/images/4/Perceptron+Model+Frank+Rosenblatt+%281957%29+-+Cornell+University.jpg" 
        alt="Perceptron model"
        style="position: relative; left: 100px; height: 500px; width: 900px;"/>

    <p>This is the perceptron model. It might be a little bit daunting at first, but let me divide the complex 
        problem into smaller manageable parts.<br><br>
        1. I'm going to start with the variables x1, x2...x4. What are they? They are the inputs from the user.
        They should me numerical, either whole(integers) or double(fractions). Imagine you have to predict
        the salary of a person based on his age. Their age is the 'x' in this case, it's called the 
        independant variable. I'm going to cover the dependant variable later. <br><br>
        2. Next thing is variables w1, w2...w4. They are called weights, hence they are noted with 'w'. 
        These are maybe the most importat things in the Deep Learning(soon). Well, if we want some result 
        from this model, what we could do? Maybe change the input, but that's not really what we want. We 
        want the input not to be changed, so what else can we change? Maybe the weight? Yes, the weights 
        can be changed in order to yield some other output(other things could too, but not now). Changing 
        the weights, you could change the output. <br><br>
        3.  opitai da napravish layouta kato tozi na github
    </p>
    
    <p>What is ML used for?</p>
</body>